version: "3.6"

services:

  medcat-snomed:
    build:
        context: ./
        dockerfile: ./docker/medcat-snomed/Dockerfile
        args:
          - CMS_MODEL_NAME=SNOMED MedCAT model
          - HTTP_PROXY=$HTTP_PROXY
          - HTTPS_PROXY=$HTTPS_PROXY
          - NO_PROXY=$NO_PROXY
    container_name: cms_medcat-snomed
    restart: always
    networks:
      - cms
    volumes:
      - ${MODEL_PACKAGE_FULL_PATH}:/app/model/model.zip:ro
      - retrained-models:/app/model/retrained
      - ./docker/medcat-snomed/.env:/app/envs/.env:ro
    environment:
      - BASE_MODEL_FULL_PATH=$MODEL_PACKAGE_FULL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow-ui:5000
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=mlflow-ui,minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=mlflow-ui,minio,localhost
    expose:
      - 8000
    ports:
      - 8180:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/info"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 60s

  medcat-icd10:
    build:
        context: ./
        dockerfile: ./docker/medcat-icd10/Dockerfile
        args:
          - CMS_MODEL_NAME=ICD-10 MedCAT model
          - HTTP_PROXY=$HTTP_PROXY
          - HTTPS_PROXY=$HTTPS_PROXY
          - NO_PROXY=$NO_PROXY
    container_name: cms_medcat-icd10
    restart: always
    networks:
      - cms
    volumes:
      - ${MODEL_PACKAGE_FULL_PATH}:/app/model/model.zip:ro
      - retrained-models:/app/model/retrained
      - ./docker/medcat-icd10/.env:/app/envs/.env:ro
    environment:
      - BASE_MODEL_FULL_PATH=$MODEL_PACKAGE_FULL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow-ui:5000
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=mlflow-ui,minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=mlflow-ui,minio,localhost
    expose:
      - 8000
    ports:
      - 8181:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/info"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 60s

  de-identification:
    build:
        context: ./
        dockerfile: ./docker/trf-deid/Dockerfile
        args:
          - CMS_MODEL_NAME=De-identification model
          - HTTP_PROXY=$HTTP_PROXY
          - HTTPS_PROXY=$HTTPS_PROXY
          - NO_PROXY=$NO_PROXY
    container_name: cms_trf-deid
    restart: always
    networks:
      - cms
    volumes:
      - ${MODEL_PACKAGE_FULL_PATH}:/app/model/model.zip:ro
      - ./docker/trf-deid/.env:/app/envs/.env:ro
    environment:
      - BASE_MODEL_FULL_PATH=$MODEL_PACKAGE_FULL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow-ui:5000
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=mlflow-ui,minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=mlflow-ui,minio,localhost
    expose:
      - 8000
    ports:
      - 8182:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/info"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 60s

  medcat-deid:
    build:
      context: ./
      dockerfile: ./docker/medcat-deid/Dockerfile
      args:
        - CMS_MODEL_NAME=De-Identification MedCAT model
        - HTTP_PROXY=$HTTP_PROXY
        - HTTPS_PROXY=$HTTPS_PROXY
        - NO_PROXY=$NO_PROXY
    container_name: cms_medcat-deid
    restart: always
    networks:
      - cms
    volumes:
      - ${MODEL_PACKAGE_FULL_PATH}:/app/model/model.zip:ro
      - retrained-models:/app/model/retrained
      - ./docker/medcat-deid/.env:/app/envs/.env:ro
    environment:
      - BASE_MODEL_FULL_PATH=$MODEL_PACKAGE_FULL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow-ui:5000
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=mlflow-ui,minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=mlflow-ui,minio,localhost
    expose:
      - 8000
    ports:
      - 8183:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/info"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 60s

  medcat-umls:
    build:
      context: ./
      dockerfile: ./docker/medcat-umls/Dockerfile
      args:
        - CMS_MODEL_NAME=UMLS MedCAT model
        - HTTP_PROXY=$HTTP_PROXY
        - HTTPS_PROXY=$HTTPS_PROXY
        - NO_PROXY=$NO_PROXY
    container_name: cms_medcat-umls
    restart: always
    networks:
      - cms
    volumes:
      - ${MODEL_PACKAGE_FULL_PATH}:/app/model/model.zip:ro
      - retrained-models:/app/model/retrained
      - ./docker/medcat-snomed/.env:/app/envs/.env:ro
    environment:
      - BASE_MODEL_FULL_PATH=$MODEL_PACKAGE_FULL_PATH
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow-ui:5000
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=mlflow-ui,minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=mlflow-ui,minio,localhost
    expose:
      - 8000
    ports:
      - 8184:8000
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/info" ]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 60s

  mlflow-db:
    image: postgres:14
    container_name: cms_mlflow-db
    restart: always
    networks:
      - cms
    environment:
      - POSTGRES_DB=mlflow-backend-store
      - POSTGRES_USER=$MLFLOW_DB_USERNAME
      - POSTGRES_PASSWORD=$MLFLOW_DB_PASSWORD
    volumes:
      - mlflow-backend-store:/var/lib/postgresql/data
    expose:
      - 5432
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}'"]
      interval: 60s
      timeout: 20s
      retries: 3

  minio:
    image: minio/minio:RELEASE.2022-06-30T20-58-09Z
    container_name: cms_minio
    restart: always
    networks:
      - cms
    volumes:
      - minio-data:/data
    environment:
      - MINIO_ROOT_USER=$AWS_ACCESS_KEY_ID
      - MINIO_ROOT_PASSWORD=$AWS_SECRET_ACCESS_KEY
      - NO_PROXY=localhost
      - no_proxy=localhost
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 60s
      timeout: 20s
      retries: 3
    expose:
      - 9000
      - 9001

  mlflow-ui:
    build:
      context: ./
      dockerfile: ./docker/mlflow/Dockerfile
      args:
        - HTTP_PROXY=$HTTP_PROXY
        - HTTPS_PROXY=$HTTPS_PROXY
        - NO_PROXY=$NO_PROXY
    container_name: cms_mlflow-ui
    restart: always
    networks:
      - cms
    environment:
      - MLFLOW_DB_USERNAME=$MLFLOW_DB_USERNAME
      - MLFLOW_DB_PASSWORD=$MLFLOW_DB_PASSWORD
      - ARTIFACTS_DESTINATION=s3://cms-model-bucket
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=minio,localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=minio,localhost
    expose:
      - 5000
    ports:
      - 8200:5000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 60s
      timeout: 20s
      retries: 3
#    depends_on:
#      - mlflow-db
#      - minio

  prometheus:
    image: prom/prometheus:v2.41.0
    container_name: cms_prometheus
    restart: always
    networks:
      - cms
    volumes:
      - ./docker/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./docker/monitoring/prometheus/alert.rules:/etc/prometheus/alert.rules
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.enable-lifecycle"
    expose:
      - 9090
    ports:
      - 8201:9090
    healthcheck:
      test: [ "CMD", "wget", "-qO-", "http://localhost:9090", "&>", "/dev/null" ]
      interval: 60s
      timeout: 20s
      retries: 3

  grafana:
    image: grafana/grafana:9.3.2-ubuntu
    container_name: cms_grafana
    restart: always
    networks:
      - cms
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./docker/monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./docker/monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - grafana-data:/var/lib/grafana
    expose:
      - 3000
    ports:
      - 8202:3000
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000/healthz" ]
      interval: 60s
      timeout: 20s
      retries: 3

  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: cms_alertmanager
    restart: always
    networks:
      - cms
    volumes:
      - ./docker/monitoring/prometheus/alertmanager.yml:/etc/alertmanager/config.yml
    command:
      - "--config.file=/etc/alertmanager/config.yml"
      - "--storage.path=/alertmanager"
    expose:
      - 9093
    ports:
      - 8203:9093
    healthcheck:
      test: [ "CMD", "wget", "-qO-", "http://localhost:9093/-/ready", "&>", "/dev/null" ]
      interval: 60s
      timeout: 20s
      retries: 3

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.46.0
    container_name: cms_cadvisor
    restart: always
    networks:
      - cms
    expose:
      - 8080
    ports:
      - 8204:8080
    volumes:
      - /:/rootfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    entrypoint: ["/usr/bin/cadvisor", "--logtostderr", "--whitelisted_container_labels=org.cogstack.model_serve"]
    healthcheck:
      test: [ "CMD", "wget", "-qO-", "http://localhost:8080/healthz", "&>", "/dev/null" ]
      interval: 60s
      timeout: 20s
      retries: 3

  proxy:
    build:
      context: ./
      dockerfile: ./docker/nginx/Dockerfile
      args:
        - HTTP_PROXY=$HTTP_PROXY
        - HTTPS_PROXY=$HTTPS_PROXY
        - NO_PROXY=$NO_PROXY
    container_name: cms_proxy
    restart: always
    networks:
      - cms
    volumes:
      - ./docker/nginx/etc/nginx/root-ca.pem:/etc/nginx/root-ca.pem:ro
      - ./docker/nginx/etc/nginx/root-ca.key:/etc/nginx/root-ca.key:ro
      - ./docker/nginx/etc/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./docker/nginx/etc/nginx/cors.conf:/etc/nginx/cors.conf:ro
      - ./docker/nginx/etc/nginx/sites-enabled/:/etc/nginx/sites-enabled/:ro
      - ./docker/nginx/etc/nginx/.htpasswd:/etc/nginx/.htpasswd
    environment:
      - HTTP_PROXY=$HTTP_PROXY
      - HTTPS_PROXY=$HTTPS_PROXY
      - NO_PROXY=localhost
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=localhost
    ports:
      - 28180:28180
      - 28181:28181
      - 28182:28182
      - 28199:28199
      - 28200:28200
      - 28201:28201
      - 28202:28202
#    depends_on:
#      - medcat-snomed
#      - medcat-icd10
#      - de-identification
#      - mlflow-ui
#      - minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 60s
      timeout: 20s
      retries: 3

volumes:
  retrained-models:
    driver: local
  mlflow-backend-store:
    driver: local
  minio-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

networks:
  cms:
    driver: bridge